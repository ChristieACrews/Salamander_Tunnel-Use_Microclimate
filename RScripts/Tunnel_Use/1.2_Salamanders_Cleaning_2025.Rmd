---
title: "1.2 Salamander Capture Data Cleaning - 2025"
author: "Christie Crews"
date: "`r Sys.Date()`"
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "HTML_reports") })
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Version of R used: `r getRversion()`
<br> 

### Project

There but geriatric? A resurvey of salamander road mitigation infrastructure in Waterton Lakes National Park 15 years after installation reveals limited use by a small number of aged salamanders

<br> 
<br>

### Overview

<br>

#### **Goal(s):**

This scripts explores my data from 2025 and prepares it to be combined with my 2024 data and an older data set (2013/2014). This involves filtering the data to just tunnel captures as I also had a study with drift fences around the lake.

Because I have recaptured individuals from 2024 and from the lakeside drift fences, I feel it will be best to separate the data into two data frames: all captures and individuals. This will make it easier to create figures showing captures by year as filtering out recaptures would remove individuals from 2024 and individuals initially captured at the lakeside drift fences.

Note that I use this script to manually fill in the SVL measurement of a lakeside to tunnel recapture (SVL was not measured at the second capture event).

<br>

#### **Details about files and pipeline:** 
<br>

1) File information 

The input file for this script is the dataset collected by myself and field assistant, G. Deadman-Wylie, in Spring 2025. The original file is "Individual_Capture_Data_20250616.xls".  I used **Excel** to delete the row of instructions for data entry and convert the spreadsheet into a csv, "Individual_Capture_Data_2025.csv".



<br>

2) File contents 


Columns in the input file: 

1)	Site: Unique site ID (categorical)

2)	SamplingDay: The number in sequence for the sampling event as sampling events cross midnight

3)	Date: Date of the capture 

4)	TimeBinary: Morning or night capture (categorical)

5)	Time: Time of the capture

6)	CaptureType: Type of capture (categorical)

7)	TrapID: The ID of the trap a salamander was capture in, if applicable (categorical). Tunnel traps are identified by a 3 character code designating tunnel number (1-4, starting at the northernmost tunnel), side of road (East or West), and trap number (1 or 2). Traps around the lake start with LL, first digit represents drift fence number (from 1 to 16 starting from northwest corner of lake going counterclockwise), character string for side of drift fence (IN: inner side towards lake; OUT: outside from lake), final digit represents trap number (from 1 to 3 going counterclockwise)

8)	CoverObjectID: The ID of the cover object a salamander was captured under, if applicable (categorical). Cover objects were numbered starting with 1 for the object

9)	NearestTunnel: The nearest tunnel to the capture location (categorical)

10) NearestFence: The nearest lakeside drift fence to the capture location (categorical)

11)	Lat_dd: Latitude of captures not at a trap

12)	Long_dd: Longitude of captures not at a trap

13)	SubstrateTemp_CaptureLocation_C: Substrate temperature recorded at the capture location

14)	SubstrateTemp_Control_C: Substrate temperature recorded at a control location

15)	Moisture_Capture: Substrate moisture measurement recorded at the capture location

16)	Moisture_Control: Substrate moisture measurement recorded

17)	HabitatType: The habitat type at a capture location at a control location

18)	SubstrateNotes: Any additional substrate notes

19)	CaptureID: The unique ID number assigned to the capture event (text)

20)	IndividualID: The unique ID number assigned to an individual (text)

21) Recapture: Whether the individual was previously captured in the current study, includes 2024 (categorical)

22)	Recapture_CurrentYear: Whether the individual was previously captured in the current year (categorical)

23)	Sex_Stage: The sex and ife stage of a captured individual

24)	SVL_mm: The snout-vent length measured to the posterior end of the vent (numeric)

25)	HeadWidth_mm: The width between the eyes of an individual (numeric)

26)	Mass_g: The mass of an individual to .01 g (numeric)

27)	TissueSample: Whether a tissue sample (tail clip) was obtained (categorical)

28)	OlderRecapture: Whether the individual was initially captured by previous study in 2013/2014 (categorical)

29) Biofluorescence: Whether an individual glowed under ultraviolet light (categorical)

30)	PhotoNumbers: The numbers of photos taken of the individual (text)

31)	Observers: Names of people who conducted the survey (text)

32)	Notes: Any additional notes (text)
</blockquote> 

<br>
<br>

### Setting up the R environment
<br>

#### Working directory: 

```{r, message =FALSE}
# setwd("/Users/fabfa/OneDrive/Documents/0 - Frogs/Natural History Note/NatHisNote_DataAnalysis")
```
  
<br>  

#### Libraries: 

```{r, message=FALSE}
# load libraries
library(tidyr)
library(tidyverse)
library(dplyr)
library(janitor)
library(lubridate)
```
  
<br>  



<br>
<br>

### Data and Analysis 

1. Load the data: 

```{r}
#load my data from 2025
all_captures_2025 <- read.csv("data_raw/Individual_Capture_Data_2025.csv")

```

2. Check number of rows and columns is as expected:

```{r}
dim(all_captures_2025)
```

Looks perfect!


<br>

3. Filter to tunnel captures and check:

```{r}
all_captures_2025 <- all_captures_2025 %>%
  filter(!is.na(NearestTunnel))

dim(all_captures_2025)
```

Looks good, there were only 19 tunnel captures by my manual count


4. Get information about the data class for each column: 

```{r}
str(all_captures_2025)
summary(all_captures_2025)
```
*We can see that we need to adjust the data classes of several columns to make them easier to work with:*

```{r}
#Turn the Date column into a date data class
all_captures_2025$Date <- as.Date(all_captures_2025$Date)


#make several columns into factors
all_captures_2025 <- all_captures_2025 %>% 
  mutate_at(c('TimeBinary', 'CaptureType', 'TrapID', 'CoverObjectID', 'NearestTunnel', 'Recapture', 'Sex_Stage', 'OlderRecapture', 'Recapture_CurrentYear'), as.factor)

#Make several columns into numbers
all_captures_2025 <- all_captures_2025 %>% 
  mutate_at(c('SVL_mm', 'HeadWidth_mm', 'Mass_g'), as.numeric)
```

5. Remove unusable columns
``` {r}
#remove extra columns that can't be used for data analysis like notes, observers, etc
all_captures_2025 <- all_captures_2025 %>% 
  select(-Notes, -NearestFence)

all_captures_2025 <- all_captures_2025 %>%
  remove_empty(whic=c("cols")) %>% #remove empty columns
  remove_empty(whic=c("rows")) #remove empty rows
```

```{r}
str(all_captures_2025)
summary(all_captures_2025)
```

*Looks like the expected number of rows and columns. All values appear normal with no obvious measurement or data entry errors present.*

6. Lakeside-Tunnel Recapture SVL

As mentioned above, there is an individual who was initially captured at the lakeside fences (when SVL was measured) who was later captured at the tunnels (SVL was not measured). Because SVL is unlikely to have changed much since the initial capture , I will manually fill in this value so I have it for my tunnel data set. The individual in question (CC25-LL035) is row 19 in the data frame

```{r}
all_captures_2025$SVL_mm[19]=73.86
```


<br>

#### Final Output

1. data frame with all captures
``` {r}
#create csv 
write.csv(all_captures_2025, "data/All_Captures_2025.csv", row.names=FALSE)

```

2. data frame with just individuals:

Here we need to be careful because of the overlap between the tunnel study and drift fence study. Instead of filtering by the Recapture or Recapture_CurrentYear columns, I am going to remove duplicate values in the IndividualID column. The following code keeps the first instance and removes rows with additional instances (i.e. individuals captured at the tunnel system more than once)

```{r}
indiv_captures_2025 <- all_captures_2025[!duplicated(all_captures_2025$IndividualID), ]

#to check
dim(indiv_captures_2025)
```
17 rows is correct (I manually noted two recapture events). I also manually viewed the data frame to confirm the correct recapture events were removed. Now we can create a csv

```{r}
write.csv(indiv_captures_2025, "data/Individual_Captures_2025.csv", row.names=FALSE)
```




<br>
<br> 

### Conclusions 

This script prepared my data for analysis and produced two data frames: one for all captures at the tunnel system and one for all individuals at the tunnel system. This data will need to be combined with my 2024 data and the 2013/2014 data.

The next step is to clean the 2013/2014 data.


<br>
<br> 

### Specific notes for the manuscript/thesis 

None

<br>
<br> 

### References 

None